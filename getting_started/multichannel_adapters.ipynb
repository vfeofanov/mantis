{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "your X_train and X_test should be of the shape (n_samples, 1, seq_len=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train dims:  (160, 10, 400)\n",
      "X_test dims:  (74, 10, 400)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = [np.load(f'../data/HandMovementDirection/{variable}_{set_name}.npy')\n",
    "        for variable in ['X', 'y'] for set_name in ['train', 'test']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = data\n",
    "\n",
    "print(\"X_train dims: \", X_train.shape)\n",
    "print(\"X_test dims: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if original sequence length is different, resize it, for example, using the following function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train dims:  (160, 10, 512)\n",
      "X_test dims:  (74, 10, 512)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def resize(X):\n",
    "    X_scaled = F.interpolate(torch.tensor(X, dtype=torch.float), size=512, mode='linear', align_corners=False)\n",
    "    return X_scaled.numpy()\n",
    "    \n",
    "X_train, X_test = resize(X_train), resize(X_test)\n",
    "\n",
    "print(\"X_train dims: \", X_train.shape)\n",
    "print(\"X_test dims: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mantis.architecture import Mantis8M\n",
    "    \n",
    "device = 'cpu' # set device\n",
    "network = Mantis8M(device=device) # init model\n",
    "network = network.from_pretrained(\"paris-noah/Mantis-8M\") # load weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract deep features with an adapter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the number of channels is too large, one approach is to reduce the dimensionality first, then pass the transformed input to the foundation model. This resembles a dimensionality reduction problem, with two key nuances:\n",
    "\n",
    " 1. The data is three-dimensional.\n",
    " 2. The dimensionality reduction algorithm should preserve the temporal patterns, as these are important for the foundation model.\n",
    " \n",
    "In this package, we provide several simple solutions to address these challenges, while leaving the development of more sophisticated and efficient solutions for future work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimension reduction along channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a 3d dataset of size $(N, D, T)$, an intuitive approach would be to reshape it to $(N, D \\times T)$ in order to apply classical dimension reduction algorithms like PCA. However, this may disrupt the temporal structure as new features will be combine different time stamps and channels at the same.\n",
    "\n",
    "Therefore, we reshape the data to $(N \\times T, D)$, allowing the dimension reduction algorithm to focus on correlations between channels over all time steps, effectively capturing spatial correlations while preserving temporal information. In the case of linear feature transformation, we eventually learn a rotation matrix $W \\in \\mathbb{R}^{D' \\times D}$ that linearly combines the original $D$ channels into new $D'$ channels, which intuitevely allows to preserve most of the temporal patterns.\n",
    "\n",
    "We have implemented this approach as a wrapper called `MultichannelProjector` that supports any 2d unsupervised dimension reduction algorithm that follows the `scikit-learn` convention with a `n_components` argument as well as `fit` and `transform` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mantis.adapters import MultichannelProjector\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "adapter = MultichannelProjector(new_num_channels=5, base_projector=PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also provided shortcuts for 3 algorithms: `PCA`, `TruncatedSVD` from `sklearn.decomposition` and `SparseRandomProjection` from `sklearn.random_projection`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for PCA\n",
    "adapter = MultichannelProjector(new_num_channels=5, base_projector='pca')\n",
    "# for TruncatedSVD\n",
    "adapter = MultichannelProjector(new_num_channels=5, base_projector='svd')\n",
    "# for SparseRandomProjection\n",
    "adapter = MultichannelProjector(new_num_channels=5, base_projector='rand')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patch-wise dimension reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As previous approach completely ignores interdependecies between the measurements at different timestamps, one simple approach to overcome this issue is to split the time dimension into non-overlapping patches. In other words, we reshape $(N, D, T)$ data into $(N \\times P, S \\times D)$, where $P$ is the number of patches, $S$ is the patch size, $T = S \\times D$, and then use a dimension reduction algorithm, which results in a projected data matrix of size $(N \\times P, S \\times D')$. Finally, we reshape the transformed input to $(N, D', T)$.\n",
    "\n",
    "This approach we implemented through an optional argument `patch_window_size` in `MultichannelProjector`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mantis.adapters import MultichannelProjector\n",
    "\n",
    "adapter = MultichannelProjector(new_num_channels=5, base_projector='pca', patch_window_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Channel selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively to dimension reduction, we can use feature selection approaches to reduce the number of channels. We have implemented a very simple approach where we reshape data to $(N \\times T, D)$, then sort the channels by variance in descending order and keep $D'$ first ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mantis.adapters import VarianceBasedSelector\n",
    "\n",
    "adapter = VarianceBasedSelector(new_num_channels=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is step is optional and depends on an application. If all channels are measured in different units, it makes sense to first scale channels before applying an adapter. \n",
    "If all channels are measured in the same units, scaling is not necessary and sometimes can be even harmful as it may change the channel importance ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional: scale training and test data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)\n",
    "X_test = scaler.transform(X_test.reshape(-1, X_test.shape[-1])).reshape(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply an adapter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All these adapters follow the same pipeline which is written as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_reduced_train dims:  (160, 5, 512)\n",
      "X_reduced_test dims:  (74, 5, 512)\n"
     ]
    }
   ],
   "source": [
    "adapter.fit(X_train)\n",
    "X_reduced_train, X_reduced_test = adapter.transform(X_train), adapter.transform(X_test)\n",
    "\n",
    "print(\"X_reduced_train dims: \", X_reduced_train.shape)\n",
    "print(\"X_reduced_test dims: \", X_reduced_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract deep features, learn a classifier and evaluate the perfomance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set is 0.36486486486486486\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from mantis.trainer import MantisTrainer\n",
    "\n",
    "model = MantisTrainer(device=device, network=network) # init trainer\n",
    "Z_train = model.transform(X_reduced_train)\n",
    "Z_test = model.transform(X_reduced_test)\n",
    "\n",
    "predictor = RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=0)\n",
    "predictor.fit(Z_train, y_train)\n",
    "y_pred = predictor.predict(Z_test)\n",
    "print(f'Accuracy on the test set is {np.mean(y_test == y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differentiable adapter for fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously, we demonstrated the use of standalone adapters, which can be applied before passing the input to the foundation model. In this section, we show how to use a differentiable adapter, implemented as a pytorch module, that is learned through backpropagation as part of the overall network.\n",
    "\n",
    "The advantage of such an adapter is that the dimensionality reduction layer is optimized according to the ultimate classification loss. However, this approach is significantly slower, as the adapter and classification head are learned jointly, requiring a forward pass through the foundation model for every optimization step — even if the foundation model's weights are frozen.\n",
    "\n",
    "We have implemented a simple adapter that applies a learnable rotation matrix $W \\in \\mathbb{R}^{D' \\times D}$, linearly combining original $D$ channels into new $D'$ channels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mantis.adapters import LinearChannelCombiner\n",
    "\n",
    "adapter = LinearChannelCombiner(num_channels=X_train.shape[1], new_num_channels=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can define your own pytorch module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class MyAdapter(nn.Module):\n",
    "    def __init__(self, num_channels, new_num_channels):\n",
    "        super().__init__()\n",
    "        self.num_channels = num_channels\n",
    "        self.new_num_channels = new_num_channels\n",
    "\n",
    "    def forward(self, x):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adapter + head fine-tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss 1.4077: 100%|███████████████████████████████████████████████████████| 10/10 [00:21<00:00,  2.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set is 0.17567567567567569\n"
     ]
    }
   ],
   "source": [
    "fine_tuning_type = 'adapter_head'\n",
    "\n",
    "# fine-tune the model\n",
    "model.fit(X_train, y_train, num_epochs=10, fine_tuning_type=fine_tuning_type, adapter=adapter)\n",
    "\n",
    "# evaluate performance\n",
    "y_pred = model.predict(X_test)\n",
    "print(f'Accuracy on the test set is {np.mean(y_test == y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss 1.2115: 100%|███████████████████████████████████████████████████████| 10/10 [00:23<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set is 0.2972972972972973\n"
     ]
    }
   ],
   "source": [
    "fine_tuning_type = 'full'\n",
    "\n",
    "# fine-tune the model\n",
    "model.fit(X_train, y_train, num_epochs=10, fine_tuning_type=fine_tuning_type, adapter=adapter)\n",
    "\n",
    "# evaluate performance\n",
    "y_pred = model.predict(X_test)\n",
    "print(f'Accuracy on the test set is {np.mean(y_test == y_pred)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
